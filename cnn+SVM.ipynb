{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb278c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "from matplotlib import image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dfab1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 150, 150, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 75, 75, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 75, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 37, 37, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 18, 18, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20736)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20736)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               10617344  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                6156      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,647,084\n",
      "Trainable params: 10,647,084\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reloaded = tf.keras.models.load_model(\n",
    "  './1671592035.h5', \n",
    "  # `custom_objects` tells keras how to load a `hub.KerasLayer`\n",
    "  #custom_objects={'KerasLayer': hub.KerasLayer}\n",
    ")\n",
    "\n",
    "reloaded.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6205e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../plant-seedlings-classification/data'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "batch_size = 100\n",
    "IMG_SHAPE = 150 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec5393c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3801 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
    "                                                 directory=train_dir,\n",
    "                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n",
    "                                                 class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f9dc2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 44s 1s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = reloaded.predict(train_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b07c1550",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk(train_dir):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9b6aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = train_dir\n",
    "classes = os.listdir(train_dir)\n",
    "IMG_SIZE=100\n",
    "CATEGORIES = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0af5e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in CATEGORIES:\n",
    "    path=os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=cv2.imread(os.path.join(path,img))\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dec80c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[]\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path=os.path.join(DATADIR, category)\n",
    "        class_num=CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array=cv2.imread(os.path.join(path,img))\n",
    "                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "                train_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a49d8475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3801"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenofimage = len(train_data)\n",
    "lenofimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "573b8b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for categories, label in train_data:\n",
    "    X.append(categories)\n",
    "    y.append(label)\n",
    "##X = tf.keras.utils.normalize(X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cd6d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd6cebbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3801, 12)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "113941e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3801,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58ee3b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel='linear',gamma='auto')\n",
    "svc.fit(predictions, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7cd20ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk(val_dir):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n",
    "\n",
    "DATADIR = val_dir\n",
    "classes = os.listdir(val_dir)\n",
    "IMG_SIZE=100\n",
    "CATEGORIES = classes\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path=os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array=cv2.imread(os.path.join(path,img))\n",
    "        break\n",
    "    break\n",
    "\n",
    "val_data=[]\n",
    "def create_val_data():\n",
    "    for category in CATEGORIES:\n",
    "        path=os.path.join(DATADIR, category)\n",
    "        class_num=CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array=cv2.imread(os.path.join(path,img))\n",
    "                new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
    "                val_data.append([new_array,class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_val_data()\n",
    "\n",
    "lenofimage = len(val_data)\n",
    "lenofimage\n",
    "\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "\n",
    "for categories, label in val_data:\n",
    "    X_test.append(categories)\n",
    "    y_test.append(label)\n",
    "##X = tf.keras.utils.normalize(X, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eef09647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 949 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
    "                                                 directory=val_dir,\n",
    "                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n",
    "                                                 class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0d7bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 10s 1s/step\n"
     ]
    }
   ],
   "source": [
    "y2 = reloaded.predict(val_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "257aa730",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = svc.predict(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79d661ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6,\n",
       "       3, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6,\n",
       "       3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 3,\n",
       "       6, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 3, 6,\n",
       "       6, 6, 6, 3, 6, 3, 6, 6, 6, 3, 6, 6, 6, 3, 6, 3, 6, 3, 6, 6, 3, 6,\n",
       "       3, 6, 3, 6, 6, 6, 3, 3, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3, 6,\n",
       "       6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6,\n",
       "       3, 6, 6, 6, 6, 6, 6, 3, 6, 6, 3, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6,\n",
       "       6, 6, 3, 6, 3, 6, 6, 3, 3, 3, 6, 6, 3, 3, 6, 6, 3, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 3, 3,\n",
       "       6, 6, 6, 3, 3, 6, 3, 6, 6, 3, 3, 6, 3, 6, 6, 6, 6, 3, 6, 6, 3, 3,\n",
       "       3, 6, 6, 6, 3, 3, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 3, 6, 3, 6, 6, 3, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3,\n",
       "       6, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       3, 6, 6, 6, 6, 3, 3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 6, 3, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 3,\n",
       "       6, 3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 3, 6, 6, 3, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6,\n",
       "       3, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 3, 3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 3, 3, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 3,\n",
       "       3, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 3, 3, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 3, 6, 6, 6, 6, 6, 6, 3,\n",
       "       6, 3, 6, 6, 3, 6, 3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 3, 6, 6, 6, 3, 3, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 3, 6, 6, 6, 6, 6, 3, 3, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 3, 6, 6, 6, 6, 6, 6, 3,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6,\n",
       "       6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 3,\n",
       "       6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 3, 6, 6, 6, 3, 3, 6, 6, 6, 6,\n",
       "       6, 3, 6, 6, 6, 3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 3, 6, 6, 3, 3, 6, 6,\n",
       "       6, 6, 6, 3, 6, 6, 6, 6, 3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 3, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 3, 3,\n",
       "       6, 6, 3, 6, 3, 6, 6, 6, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6aa564ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on unknown data is 0.1475237091675448\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on unknown data is\",accuracy_score(y_test,y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abedc4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
